{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AleksandreBakhtadze/ML-abakh22-facial-expression-recognition/blob/main/facial_expression_train3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qf9vWdXNP_AF",
        "outputId": "8313dcac-ecfc-4b14-8ec1-3326204e0f11"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "rvTGhVSzkkxT"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle\n",
        "!pip install -q wandb\n",
        "!pip install -q torchmetrics\n",
        "!pip install -q albumentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcJz7VoUpteu",
        "outputId": "7375f3ae-2259-4a06-9272-c5af60b1321c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "challenges-in-representation-learning-facial-expression-recognition-challenge.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "replace example_submission.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
          ]
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.login()\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c challenges-in-representation-learning-facial-expression-recognition-challenge\n",
        "!unzip -q challenges-in-representation-learning-facial-expression-recognition-challenge.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "W5AAtI1pvEci"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torchmetrics.classification import MulticlassConfusionMatrix, MulticlassPrecision, MulticlassRecall, MulticlassF1Score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from torchsummary import summary\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV\n",
        "df = pd.read_csv(\"train.csv\")\n",
        "\n",
        "# Example row\n",
        "print(df.head())\n",
        "\n",
        "# Convert the pixel values to image tensors\n",
        "def process_row(row):\n",
        "    pixels = np.array([int(p) for p in row['pixels'].split()], dtype=np.uint8).reshape(48, 48)\n",
        "    img = Image.fromarray(pixels)\n",
        "    return img, int(row['emotion'])\n",
        "\n",
        "images, labels = zip(*[process_row(row) for _, row in df.iterrows()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdcpG1aPLqs3",
        "outputId": "a7ce9208-7ee4-4353-f5d6-b313547d81f0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   emotion                                             pixels\n",
            "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...\n",
            "1        0  151 150 147 155 148 133 111 140 170 174 182 15...\n",
            "2        2  231 212 156 164 174 138 161 173 182 200 106 38...\n",
            "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...\n",
            "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define separate transforms for training and validation\n",
        "train_transform = A.Compose([\n",
        "    A.Rotate(limit=15, p=0.5),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.3),\n",
        "    A.Normalize(mean=[0.5], std=[0.5]),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "val_transform = A.Compose([\n",
        "    A.Normalize(mean=[0.5], std=[0.5]),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "class FERDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, images, labels, transform=None):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "        img = np.array(img)  # Convert PIL image to numpy for albumentations\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=img)\n",
        "            img = augmented['image']\n",
        "        return img, label\n",
        "\n",
        "# Split into train and val\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_imgs, val_imgs, train_labels, val_labels = train_test_split(images, labels, test_size=0.1, stratify=labels)\n",
        "\n",
        "train_dataset = FERDataset(train_imgs, train_labels, train_transform)\n",
        "val_dataset = FERDataset(val_imgs, val_labels, val_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)  # Increased batch size\n",
        "val_loader = DataLoader(val_dataset, batch_size=128)"
      ],
      "metadata": {
        "id": "zPeFplGtLq2T"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImprovedCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImprovedCNN, self).__init__()\n",
        "        self.conv_block1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.conv_block2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.conv_block3 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.dropout = nn.Dropout(0.4)  # Reduced dropout rate\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(256 * 6 * 6, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(512, 7)  # 7 emotion classes\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_block1(x)\n",
        "        x = self.conv_block2(x)\n",
        "        x = self.conv_block3(x)\n",
        "        x = self.dropout(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = ImprovedCNN().to(device)\n",
        "summary(model, (1, 48, 48))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYYw3h4PLq7l",
        "outputId": "c1e6971d-1c28-4ba5-e941-b34e762ca270"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 48, 48]             640\n",
            "       BatchNorm2d-2           [-1, 64, 48, 48]             128\n",
            "              ReLU-3           [-1, 64, 48, 48]               0\n",
            "            Conv2d-4           [-1, 64, 48, 48]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 48, 48]             128\n",
            "              ReLU-6           [-1, 64, 48, 48]               0\n",
            "         MaxPool2d-7           [-1, 64, 24, 24]               0\n",
            "            Conv2d-8          [-1, 128, 24, 24]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 24, 24]             256\n",
            "             ReLU-10          [-1, 128, 24, 24]               0\n",
            "           Conv2d-11          [-1, 128, 24, 24]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 24, 24]             256\n",
            "             ReLU-13          [-1, 128, 24, 24]               0\n",
            "        MaxPool2d-14          [-1, 128, 12, 12]               0\n",
            "           Conv2d-15          [-1, 256, 12, 12]         295,168\n",
            "      BatchNorm2d-16          [-1, 256, 12, 12]             512\n",
            "             ReLU-17          [-1, 256, 12, 12]               0\n",
            "           Conv2d-18          [-1, 256, 12, 12]         590,080\n",
            "      BatchNorm2d-19          [-1, 256, 12, 12]             512\n",
            "             ReLU-20          [-1, 256, 12, 12]               0\n",
            "        MaxPool2d-21            [-1, 256, 6, 6]               0\n",
            "          Dropout-22            [-1, 256, 6, 6]               0\n",
            "           Linear-23                 [-1, 1024]       9,438,208\n",
            "             ReLU-24                 [-1, 1024]               0\n",
            "          Dropout-25                 [-1, 1024]               0\n",
            "           Linear-26                  [-1, 512]         524,800\n",
            "             ReLU-27                  [-1, 512]               0\n",
            "          Dropout-28                  [-1, 512]               0\n",
            "           Linear-29                    [-1, 7]           3,591\n",
            "================================================================\n",
            "Total params: 11,112,647\n",
            "Trainable params: 11,112,647\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 12.41\n",
            "Params size (MB): 42.39\n",
            "Estimated Total Size (MB): 54.81\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample 20 training examples\n",
        "small_dataset, _ = torch.utils.data.random_split(train_dataset, [20, len(train_dataset) - 20])\n",
        "small_loader = torch.utils.data.DataLoader(small_dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "# Re-initialize the model\n",
        "model = ImprovedCNN().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Start Wandb for overfitting test\n",
        "wandb.init(project=\"FER-CNN\", name=\"overfit_test\")\n",
        "\n",
        "print(\"Training on a tiny dataset to check overfitting...\")\n",
        "for epoch in range(20):\n",
        "    model.train()\n",
        "    total_loss, correct = 0, 0\n",
        "    for imgs, labels in small_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        outputs = model(imgs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        correct += (outputs.argmax(1) == labels).sum().item()\n",
        "\n",
        "    acc = correct / len(small_loader.dataset)\n",
        "    wandb.log({\"overfit_epoch\": epoch + 1, \"overfit_loss\": total_loss, \"overfit_acc\": acc})\n",
        "    print(f\"Epoch {epoch+1} - Loss: {total_loss:.4f}, Acc: {acc:.4f}\")\n",
        "    if acc >= 0.95:  # Relaxed threshold to account for deeper model\n",
        "        print(\"✅ Model successfully overfit tiny dataset\")\n",
        "        break\n",
        "\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        },
        "id": "DuGPD0QfSMJT",
        "outputId": "3b41f2c3-3755-459c-a469-7d6f29eeafa5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">improved_cnn_run</strong> at: <a href='https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN/runs/xljbhjup' target=\"_blank\">https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN/runs/xljbhjup</a><br> View project at: <a href='https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN' target=\"_blank\">https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250607_124708-xljbhjup/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250607_125551-c0gm04hm</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN/runs/c0gm04hm' target=\"_blank\">overfit_test</a></strong> to <a href='https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN' target=\"_blank\">https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN/runs/c0gm04hm' target=\"_blank\">https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN/runs/c0gm04hm</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on a tiny dataset to check overfitting...\n",
            "Epoch 1 - Loss: 35.4556, Acc: 0.4000\n",
            "Epoch 2 - Loss: 16.7016, Acc: 0.2500\n",
            "Epoch 3 - Loss: 15.8338, Acc: 0.5500\n",
            "Epoch 4 - Loss: 11.7996, Acc: 0.6000\n",
            "Epoch 5 - Loss: 6.8095, Acc: 0.4000\n",
            "Epoch 6 - Loss: 6.7574, Acc: 0.3500\n",
            "Epoch 7 - Loss: 6.9952, Acc: 0.6000\n",
            "Epoch 8 - Loss: 6.8201, Acc: 0.6500\n",
            "Epoch 9 - Loss: 5.1638, Acc: 0.4500\n",
            "Epoch 10 - Loss: 6.6056, Acc: 0.4000\n",
            "Epoch 11 - Loss: 4.5113, Acc: 0.6500\n",
            "Epoch 12 - Loss: 6.5261, Acc: 0.5000\n",
            "Epoch 13 - Loss: 7.6441, Acc: 0.5500\n",
            "Epoch 14 - Loss: 5.7156, Acc: 0.6000\n",
            "Epoch 15 - Loss: 5.5162, Acc: 0.6500\n",
            "Epoch 16 - Loss: 4.9310, Acc: 0.6500\n",
            "Epoch 17 - Loss: 6.0052, Acc: 0.5500\n",
            "Epoch 18 - Loss: 4.5700, Acc: 0.6500\n",
            "Epoch 19 - Loss: 4.3062, Acc: 0.7000\n",
            "Epoch 20 - Loss: 5.6484, Acc: 0.6500\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>overfit_acc</td><td>▃▁▆▆▃▃▆▇▄▃▇▅▆▆▇▇▆▇█▇</td></tr><tr><td>overfit_epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>overfit_loss</td><td>█▄▄▃▂▂▂▂▁▂▁▁▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>overfit_acc</td><td>0.65</td></tr><tr><td>overfit_epoch</td><td>20</td></tr><tr><td>overfit_loss</td><td>5.64839</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">overfit_test</strong> at: <a href='https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN/runs/c0gm04hm' target=\"_blank\">https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN/runs/c0gm04hm</a><br> View project at: <a href='https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN' target=\"_blank\">https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250607_125551-c0gm04hm/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Start Wandb\n",
        "wandb.init(project=\"FER-CNN\", name=\"improved_cnn_run\", config={\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"batch_size\": 128,\n",
        "    \"epochs\": 30,  # Increased epochs\n",
        "    \"architecture\": \"ImprovedCNN\",\n",
        "    \"optimizer\": \"Adam\"\n",
        "})\n",
        "\n",
        "# Watch model gradients and parameters\n",
        "wandb.watch(model, criterion=criterion, log=\"all\", log_freq=100)\n",
        "\n",
        "# Loss, optimizer, and scheduler\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
        "\n",
        "# Early stopping parameters\n",
        "best_val_acc = 0.0\n",
        "patience = 5\n",
        "patience_counter = 0\n",
        "\n",
        "# Metrics for logging\n",
        "conf_matrix = MulticlassConfusionMatrix(num_classes=7).to(device)\n",
        "precision = MulticlassPrecision(num_classes=7, average=None).to(device)\n",
        "recall = MulticlassRecall(num_classes=7, average=None).to(device)\n",
        "f1 = MulticlassF1Score(num_classes=7, average=None).to(device)\n",
        "\n",
        "for epoch in range(30):\n",
        "    model.train()\n",
        "    train_loss, correct = 0, 0\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        outputs = model(imgs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        correct += (outputs.argmax(1) == labels).sum().item()\n",
        "\n",
        "    train_acc = correct / len(train_loader.dataset)\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    val_loss, val_correct = 0, 0\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in val_loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            preds = outputs.argmax(1)\n",
        "            val_correct += (preds == labels).sum().item()\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            # Update metrics\n",
        "            conf_matrix.update(preds, labels)\n",
        "            precision.update(preds, labels)\n",
        "            recall.update(preds, labels)\n",
        "            f1.update(preds, labels)\n",
        "\n",
        "    val_acc = val_correct / len(val_loader.dataset)\n",
        "\n",
        "    # Compute per-class metrics\n",
        "    cm = conf_matrix.compute().cpu().numpy()\n",
        "    prec_scores = precision.compute().cpu().numpy()\n",
        "    rec_scores = recall.compute().cpu().numpy()\n",
        "    f1_scores = f1.compute().cpu().numpy()\n",
        "\n",
        "    # Log metrics to Wandb\n",
        "    wandb.log({\n",
        "        \"epoch\": epoch + 1,\n",
        "        \"train_loss\": train_loss / len(train_loader),\n",
        "        \"train_acc\": train_acc,\n",
        "        \"val_loss\": val_loss / len(val_loader),\n",
        "        \"val_acc\": val_acc,\n",
        "        \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
        "        **{f\"precision_class_{i}\": prec_scores[i] for i in range(7)},\n",
        "        **{f\"recall_class_{i}\": rec_scores[i] for i in range(7)},\n",
        "        **{f\"f1_class_{i}\": f1_scores[i] for i in range(7)}\n",
        "    })\n",
        "\n",
        "    print(f\"Epoch {epoch+1} - Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Val Loss: {val_loss / len(val_loader):.4f}\")\n",
        "\n",
        "    # Learning rate scheduling\n",
        "    scheduler.step(val_loss / len(val_loader))\n",
        "\n",
        "    # Early stopping\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        patience_counter = 0\n",
        "        torch.save(model.state_dict(), \"best_model.pth\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= patience:\n",
        "            print(\"Early stopping triggered\")\n",
        "            break\n",
        "\n",
        "    # Reset metrics for next epoch\n",
        "    conf_matrix.reset()\n",
        "    precision.reset()\n",
        "    recall.reset()\n",
        "    f1.reset()\n",
        "\n",
        "# Load best model for evaluation\n",
        "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
        "\n",
        "# Final evaluation\n",
        "model.eval()\n",
        "all_preds, all_labels = [], []\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in val_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        outputs = model(imgs)\n",
        "        preds = outputs.argmax(1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
        "ax.set_xlabel(\"Predicted\")\n",
        "ax.set_ylabel(\"True\")\n",
        "ax.set_title(\"Confusion Matrix\")\n",
        "wandb.log({\"confusion_matrix\": wandb.Image(fig)})\n",
        "plt.close(fig)\n",
        "\n",
        "# Classification report\n",
        "report = classification_report(all_labels, all_preds, digits=4, target_names=['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral'])\n",
        "print(report)\n",
        "wandb.run.summary[\"classification_report\"] = report\n",
        "\n",
        "# Sample predictions\n",
        "model.eval()\n",
        "for i in range(5):\n",
        "    img, label = val_dataset[i]\n",
        "    with torch.no_grad():\n",
        "        pred = model(img.unsqueeze(0).to(device)).argmax(1).item()\n",
        "    img_np = img.squeeze().numpy()\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.imshow(img_np, cmap=\"gray\")\n",
        "    ax.set_title(f\"Predicted: {pred}, True: {label}\")\n",
        "    ax.axis('off')\n",
        "    wandb.log({f\"Example_{i}\": wandb.Image(fig)})\n",
        "    plt.close(fig)\n",
        "\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Qym8e1IWL2CG",
        "outputId": "1dd82e20-d035-4b15-f972-c5d52b9efa40"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250607_125912-upfpnh8z</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN/runs/upfpnh8z' target=\"_blank\">improved_cnn_run</a></strong> to <a href='https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN' target=\"_blank\">https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN/runs/upfpnh8z' target=\"_blank\">https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN/runs/upfpnh8z</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Train Acc: 0.2437, Val Acc: 0.2557, Val Loss: 1.8002\n",
            "Epoch 2 - Train Acc: 0.2631, Val Acc: 0.2870, Val Loss: 1.7648\n",
            "Epoch 3 - Train Acc: 0.3234, Val Acc: 0.3762, Val Loss: 1.5355\n",
            "Epoch 4 - Train Acc: 0.3820, Val Acc: 0.4204, Val Loss: 1.4782\n",
            "Epoch 5 - Train Acc: 0.4134, Val Acc: 0.4326, Val Loss: 1.4167\n",
            "Epoch 6 - Train Acc: 0.4218, Val Acc: 0.4417, Val Loss: 1.4241\n",
            "Epoch 7 - Train Acc: 0.4279, Val Acc: 0.4535, Val Loss: 1.3630\n",
            "Epoch 8 - Train Acc: 0.4367, Val Acc: 0.4580, Val Loss: 1.3522\n",
            "Epoch 9 - Train Acc: 0.4407, Val Acc: 0.4521, Val Loss: 1.3834\n",
            "Epoch 10 - Train Acc: 0.4446, Val Acc: 0.4615, Val Loss: 1.3395\n",
            "Epoch 11 - Train Acc: 0.4497, Val Acc: 0.4678, Val Loss: 1.3217\n",
            "Epoch 12 - Train Acc: 0.4537, Val Acc: 0.4535, Val Loss: 1.2968\n",
            "Epoch 13 - Train Acc: 0.4553, Val Acc: 0.4869, Val Loss: 1.2966\n",
            "Epoch 14 - Train Acc: 0.4618, Val Acc: 0.4845, Val Loss: 1.2759\n",
            "Epoch 15 - Train Acc: 0.4716, Val Acc: 0.5037, Val Loss: 1.2549\n",
            "Epoch 16 - Train Acc: 0.4741, Val Acc: 0.5026, Val Loss: 1.3012\n",
            "Epoch 17 - Train Acc: 0.4837, Val Acc: 0.5350, Val Loss: 1.2202\n",
            "Epoch 18 - Train Acc: 0.5016, Val Acc: 0.5430, Val Loss: 1.2691\n",
            "Epoch 19 - Train Acc: 0.5043, Val Acc: 0.5496, Val Loss: 1.2271\n",
            "Epoch 20 - Train Acc: 0.5130, Val Acc: 0.5343, Val Loss: 1.2127\n",
            "Epoch 21 - Train Acc: 0.5188, Val Acc: 0.5688, Val Loss: 1.1667\n",
            "Epoch 22 - Train Acc: 0.5281, Val Acc: 0.5319, Val Loss: 1.2135\n",
            "Epoch 23 - Train Acc: 0.5355, Val Acc: 0.5653, Val Loss: 1.1752\n",
            "Epoch 24 - Train Acc: 0.5444, Val Acc: 0.5806, Val Loss: 1.1642\n",
            "Epoch 25 - Train Acc: 0.5510, Val Acc: 0.5911, Val Loss: 1.1414\n",
            "Epoch 26 - Train Acc: 0.5582, Val Acc: 0.5855, Val Loss: 1.1400\n",
            "Epoch 27 - Train Acc: 0.5637, Val Acc: 0.6022, Val Loss: 1.1036\n",
            "Epoch 28 - Train Acc: 0.5711, Val Acc: 0.5667, Val Loss: 1.1956\n",
            "Epoch 29 - Train Acc: 0.5754, Val Acc: 0.5918, Val Loss: 1.1345\n",
            "Epoch 30 - Train Acc: 0.5792, Val Acc: 0.5946, Val Loss: 1.0893\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Angry     0.5654    0.3684    0.4461       399\n",
            "     Disgust     0.0000    0.0000    0.0000        44\n",
            "        Fear     0.4340    0.3049    0.3582       410\n",
            "       Happy     0.8869    0.8255    0.8551       722\n",
            "         Sad     0.4076    0.6853    0.5112       483\n",
            "    Surprise     0.8000    0.6562    0.7210       317\n",
            "     Neutral     0.5561    0.6492    0.5991       496\n",
            "\n",
            "    accuracy                         0.6022      2871\n",
            "   macro avg     0.5214    0.4985    0.4987      2871\n",
            "weighted avg     0.6166    0.6022    0.5973      2871\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>f1_class_0</td><td>▁▁▁▁▁▁▁▁▁▂▁▁▃▃▃▄▅▆▆▇▇▇▇██▇███▇</td></tr><tr><td>f1_class_1</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>f1_class_2</td><td>▁▁▃▂▄▅▅▄▄▄▆▅▅▅▆▄▆▆▇▆▆▆▇▇█▇████</td></tr><tr><td>f1_class_3</td><td>▁▂▄▄▆▆▆▇▇▇▇▇▇▇▇▇▇██▇██████████</td></tr><tr><td>f1_class_4</td><td>▁▂▅▆▆▄▇▄▇▄▇▁▄▇▇▇▇▇▇▇▇██▇█████▇</td></tr><tr><td>f1_class_5</td><td>▁▃▅▇▆▇▇▇▇▇▇▇▇██▇█▇▇▅█▄██▇██▇▇█</td></tr><tr><td>f1_class_6</td><td>▁▁▃▅▂▆▂▆▂▆▄▅▆▃▅▅▇▇▇▇█▇▇██▇█▇██</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>precision_class_0</td><td>▁▁▁▁▁▁▁█▂▆▇▄▃▃▄▄▅▄▄▅▄▄▅▄▄▅▅▄▅▅</td></tr><tr><td>precision_class_1</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>precision_class_2</td><td>▁▁▄▄▄▆▅▅▆▅▅▅▆▆▆▆▇▇▆▆▇▆▇▇█▇█▇█▇</td></tr><tr><td>precision_class_3</td><td>▁▂▄▄▅▆▆▆▆▆▇▆▇▆▆▇▆█▇▆▇▇████████</td></tr><tr><td>precision_class_4</td><td>▁▇▆▆▆▆▆▆▆▅▆▆▇▆▆▆▇▇▇▇█▇▇████▇██</td></tr><tr><td>precision_class_5</td><td>▂▁▂▆▄▆▅▆▆▅▅▅▆▆▆▇▆▇▇█▆█▆▇▇▆▇█▇▆</td></tr><tr><td>precision_class_6</td><td>▁▁▄▄▄▄▄▄▃▄▄▄▄▆▅▆▆▆▆▅▆▇▆▆▇▇▇█▇▇</td></tr><tr><td>recall_class_0</td><td>▁▁▁▁▁▁▁▁▁▂▁▁▂▃▂▃▃▅▅▅▇█▅▇▇▆▆█▆▆</td></tr><tr><td>recall_class_1</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>recall_class_2</td><td>▁▁▃▂▄▄▄▃▃▃▆▅▄▄▅▄▅▅▇▆▆▆▆▆▇▇▇▇▇█</td></tr><tr><td>recall_class_3</td><td>█▁▁▄▃▁▄▂▄▄▄▄▅▅▆▄▅▂▄▅▄▄▃▂▄▄▃▃▄▄</td></tr><tr><td>recall_class_4</td><td>▁▂▄▅▆▃▇▃█▂▆▁▂▇▆█▆▇▆▅▅▆▇▆▆▇▇▇▇▅</td></tr><tr><td>recall_class_5</td><td>▁▇█▆█▆█▇▇▇██▆▇▇▅▇▆▅▄▇▃▇▇▆▇▆▅▆▇</td></tr><tr><td>recall_class_6</td><td>▁▁▂▄▂█▁█▁▇▂▇█▂▃▄▆▆▆▇▇▅▆▇▆▅▇▄▆▇</td></tr><tr><td>train_acc</td><td>▁▁▃▄▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇█████</td></tr><tr><td>train_loss</td><td>█▇▆▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▂▃▄▅▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇████▇██</td></tr><tr><td>val_loss</td><td>██▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▁▁▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>classification_report</td><td>              precis...</td></tr><tr><td>epoch</td><td>30</td></tr><tr><td>f1_class_0</td><td>0.43087</td></tr><tr><td>f1_class_1</td><td>0</td></tr><tr><td>f1_class_2</td><td>0.34932</td></tr><tr><td>f1_class_3</td><td>0.86171</td></tr><tr><td>f1_class_4</td><td>0.46911</td></tr><tr><td>f1_class_5</td><td>0.73684</td></tr><tr><td>f1_class_6</td><td>0.58889</td></tr><tr><td>learning_rate</td><td>0.001</td></tr><tr><td>precision_class_0</td><td>0.6009</td></tr><tr><td>precision_class_1</td><td>0</td></tr><tr><td>precision_class_2</td><td>0.35236</td></tr><tr><td>precision_class_3</td><td>0.86471</td></tr><tr><td>precision_class_4</td><td>0.41325</td></tr><tr><td>precision_class_5</td><td>0.74516</td></tr><tr><td>precision_class_6</td><td>0.54452</td></tr><tr><td>recall_class_0</td><td>0.33584</td></tr><tr><td>recall_class_1</td><td>0</td></tr><tr><td>recall_class_2</td><td>0.34634</td></tr><tr><td>recall_class_3</td><td>0.85873</td></tr><tr><td>recall_class_4</td><td>0.54244</td></tr><tr><td>recall_class_5</td><td>0.72871</td></tr><tr><td>recall_class_6</td><td>0.64113</td></tr><tr><td>train_acc</td><td>0.57922</td></tr><tr><td>train_loss</td><td>1.11059</td></tr><tr><td>val_acc</td><td>0.59457</td></tr><tr><td>val_loss</td><td>1.08934</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">improved_cnn_run</strong> at: <a href='https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN/runs/upfpnh8z' target=\"_blank\">https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN/runs/upfpnh8z</a><br> View project at: <a href='https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN' target=\"_blank\">https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN</a><br>Synced 5 W&B file(s), 6 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250607_125912-upfpnh8z/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YjWQjq7PeYhq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPEGMZZilOIXby/gdpMNQyc",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}