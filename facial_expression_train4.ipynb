{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AleksandreBakhtadze/ML-abakh22-facial-expression-recognition/blob/main/facial_expression_train4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qf9vWdXNP_AF",
        "outputId": "1c0a4b54-eb80-49b4-d1d8-01c9200fd88d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rvTGhVSzkkxT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cdd9658-04a1-4d39-d46a-2dc280a7d25e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m962.5/962.5 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m122.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m92.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q kaggle\n",
        "!pip install -q wandb\n",
        "!pip install -q torchmetrics\n",
        "!pip install -q albumentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "EcJz7VoUpteu",
        "outputId": "26fcfb13-e27a-480f-a473-f38a385fc1f5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mabakh22\u001b[0m (\u001b[33mabakh22-free-university-of-tbilisi-\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading challenges-in-representation-learning-facial-expression-recognition-challenge.zip to /content\n",
            " 92% 262M/285M [00:00<00:00, 290MB/s]\n",
            "100% 285M/285M [00:00<00:00, 316MB/s]\n"
          ]
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.login()\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c challenges-in-representation-learning-facial-expression-recognition-challenge\n",
        "!unzip -q challenges-in-representation-learning-facial-expression-recognition-challenge.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "W5AAtI1pvEci"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torchmetrics.classification import MulticlassConfusionMatrix, MulticlassPrecision, MulticlassRecall, MulticlassF1Score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from torchsummary import summary\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import albumentations as A\n",
        "import torch.nn.functional as F\n",
        "from albumentations.pytorch import ToTensorV2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV\n",
        "df = pd.read_csv(\"train.csv\")\n",
        "\n",
        "# Example row\n",
        "print(df.head())\n",
        "\n",
        "# Convert the pixel values to image tensors\n",
        "def process_row(row):\n",
        "    pixels = np.array([int(p) for p in row['pixels'].split()], dtype=np.uint8).reshape(48, 48)\n",
        "    img = Image.fromarray(pixels)\n",
        "    return img, int(row['emotion'])\n",
        "\n",
        "images, labels = zip(*[process_row(row) for _, row in df.iterrows()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdcpG1aPLqs3",
        "outputId": "61c8b4aa-c5b5-40a7-95b7-615cce08c1b7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   emotion                                             pixels\n",
            "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...\n",
            "1        0  151 150 147 155 148 133 111 140 170 174 182 15...\n",
            "2        2  231 212 156 164 174 138 161 173 182 200 106 38...\n",
            "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...\n",
            "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define separate transforms for training and validation\n",
        "# Enhanced transforms\n",
        "train_transform = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
        "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
        "    A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n",
        "    A.CoarseDropout(max_holes=8, max_height=8, max_width=8, fill_value=0, p=0.3),\n",
        "    A.Normalize(mean=[0.485], std=[0.229]),  # Using standard ImageNet stats\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "val_transform = A.Compose([\n",
        "    A.Normalize(mean=[0.485], std=[0.229]),\n",
        "    ToTensorV2()\n",
        "])\n",
        "class FERDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, images, labels, transform=None):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img = self.images[index]  # Fixed: Changed 'idx' to 'index'\n",
        "        img = np.array(self.images[index])\n",
        "        label = self.labels[index]\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=img)\n",
        "            img = augmented['image']\n",
        "        return img, label\n",
        "\n",
        "# Split into train and val\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "train_imgs, val_imgs, train_labels, val_labels = train_test_split(images, labels, test_size=0.1, stratify=labels, random_state=42)\n",
        "\n",
        "# Add WeightedRandomSampler for class imbalance\n",
        "class_counts = Counter(train_labels)\n",
        "num_samples = len(train_labels)\n",
        "class_weights = {i: num_samples / (len(class_counts) * count) for i, count in class_counts.items()}\n",
        "sample_weights = [class_weights[label] for label in train_labels]\n",
        "sampler = torch.utils.data.WeightedRandomSampler(sample_weights, num_samples)\n",
        "\n",
        "train_dataset = FERDataset(train_imgs, train_labels, train_transform)\n",
        "val_dataset = FERDataset(val_imgs, val_labels, val_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, sampler=sampler)  # Use sampler\n",
        "val_loader = DataLoader(val_dataset, batch_size=32)  # Smaller batch size for validation"
      ],
      "metadata": {
        "id": "zPeFplGtLq2T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88f109fa-a21c-4c74-a67f-e14d7bb40999"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "<ipython-input-20-7722ad1ccef0>:7: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
            "  A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n",
            "<ipython-input-20-7722ad1ccef0>:8: UserWarning: Argument(s) 'max_holes, max_height, max_width, fill_value' are not valid for transform CoarseDropout\n",
            "  A.CoarseDropout(max_holes=8, max_height=8, max_width=8, fill_value=0, p=0.3),\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicFERModel(nn.Module):\n",
        "    def __init__(self, num_classes=7):\n",
        "        super(BasicFERModel, self).__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(0.25),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(0.25),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(0.25)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(128 * 6 * 6, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = BasicFERModel().to(device)\n",
        "summary(model, (1, 48, 48))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYYw3h4PLq7l",
        "outputId": "b51d5d51-fcc0-4674-f5f1-5ca9a2c0dd3a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 48, 48]             320\n",
            "       BatchNorm2d-2           [-1, 32, 48, 48]              64\n",
            "              ReLU-3           [-1, 32, 48, 48]               0\n",
            "         MaxPool2d-4           [-1, 32, 24, 24]               0\n",
            "           Dropout-5           [-1, 32, 24, 24]               0\n",
            "            Conv2d-6           [-1, 64, 24, 24]          18,496\n",
            "       BatchNorm2d-7           [-1, 64, 24, 24]             128\n",
            "              ReLU-8           [-1, 64, 24, 24]               0\n",
            "         MaxPool2d-9           [-1, 64, 12, 12]               0\n",
            "          Dropout-10           [-1, 64, 12, 12]               0\n",
            "           Conv2d-11          [-1, 128, 12, 12]          73,856\n",
            "      BatchNorm2d-12          [-1, 128, 12, 12]             256\n",
            "             ReLU-13          [-1, 128, 12, 12]               0\n",
            "        MaxPool2d-14            [-1, 128, 6, 6]               0\n",
            "          Dropout-15            [-1, 128, 6, 6]               0\n",
            "           Linear-16                  [-1, 256]       1,179,904\n",
            "      BatchNorm1d-17                  [-1, 256]             512\n",
            "             ReLU-18                  [-1, 256]               0\n",
            "          Dropout-19                  [-1, 256]               0\n",
            "           Linear-20                    [-1, 7]           1,799\n",
            "================================================================\n",
            "Total params: 1,275,335\n",
            "Trainable params: 1,275,335\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 3.45\n",
            "Params size (MB): 4.87\n",
            "Estimated Total Size (MB): 8.33\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a small subset of the training set to test overfitting\n",
        "small_indices = list(range(64))  # Tiny sample size\n",
        "small_dataset = torch.utils.data.Subset(train_dataset, small_indices)\n",
        "small_loader = DataLoader(small_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "def test_overfitting():\n",
        "    class TinyModel(nn.Module):\n",
        "        def __init__(self, num_classes=7):\n",
        "            super(TinyModel, self).__init__()\n",
        "            self.conv = nn.Conv2d(1, 8, kernel_size=3, padding=1)\n",
        "            self.pool = nn.MaxPool2d(2)\n",
        "            self.fc = nn.Linear(8*24*24, num_classes)\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = self.pool(F.relu(self.conv(x)))\n",
        "            x = x.view(x.size(0), -1)\n",
        "            x = self.fc(x)\n",
        "            return x\n",
        "\n",
        "    wandb.init(project=\"FER-CNN\", name=\"overfit_test_v4\")\n",
        "\n",
        "    model = TinyModel().to(device)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    print(\"Training on small dataset to check overfitting...\")\n",
        "    for epoch in range(50):\n",
        "        model.train()\n",
        "        total_loss, correct = 0, 0\n",
        "\n",
        "        for inputs, labels in small_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            correct += (outputs.argmax(1) == labels).sum().item()\n",
        "\n",
        "        acc = correct / len(small_dataset)\n",
        "        wandb.log({\n",
        "            \"overfit_epoch\": epoch + 1,\n",
        "            \"overfit_loss\": total_loss,\n",
        "            \"overfit_acc\": acc\n",
        "        })\n",
        "\n",
        "        print(f\"Epoch {epoch+1} - Loss: {total_loss:.4f}, Acc: {acc:.4f}\")\n",
        "        if acc >= 0.95:\n",
        "            print(\"✅ Model successfully overfit small dataset\")\n",
        "            break\n",
        "\n",
        "    wandb.finish()\n",
        "\n",
        "test_overfitting()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DuGPD0QfSMJT",
        "outputId": "b18f653b-161e-426a-e6ce-76a5d104c35c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250607_152029-s4275988</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN/runs/s4275988' target=\"_blank\">overfit_test_v4</a></strong> to <a href='https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN' target=\"_blank\">https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN/runs/s4275988' target=\"_blank\">https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN/runs/s4275988</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on small dataset to check overfitting...\n",
            "Epoch 1 - Loss: 9.4222, Acc: 0.1250\n",
            "Epoch 2 - Loss: 8.5299, Acc: 0.2344\n",
            "Epoch 3 - Loss: 7.8905, Acc: 0.3281\n",
            "Epoch 4 - Loss: 6.8035, Acc: 0.3125\n",
            "Epoch 5 - Loss: 8.1665, Acc: 0.2656\n",
            "Epoch 6 - Loss: 8.3051, Acc: 0.3438\n",
            "Epoch 7 - Loss: 9.3703, Acc: 0.2188\n",
            "Epoch 8 - Loss: 6.8226, Acc: 0.2969\n",
            "Epoch 9 - Loss: 7.2416, Acc: 0.2812\n",
            "Epoch 10 - Loss: 7.8369, Acc: 0.3125\n",
            "Epoch 11 - Loss: 6.4243, Acc: 0.4062\n",
            "Epoch 12 - Loss: 6.3565, Acc: 0.3281\n",
            "Epoch 13 - Loss: 7.1413, Acc: 0.2656\n",
            "Epoch 14 - Loss: 6.7042, Acc: 0.3594\n",
            "Epoch 15 - Loss: 6.5307, Acc: 0.4062\n",
            "Epoch 16 - Loss: 6.5642, Acc: 0.4219\n",
            "Epoch 17 - Loss: 5.8726, Acc: 0.5000\n",
            "Epoch 18 - Loss: 6.0906, Acc: 0.3906\n",
            "Epoch 19 - Loss: 5.9835, Acc: 0.3906\n",
            "Epoch 20 - Loss: 5.7056, Acc: 0.4375\n",
            "Epoch 21 - Loss: 5.3460, Acc: 0.4688\n",
            "Epoch 22 - Loss: 5.3666, Acc: 0.4844\n",
            "Epoch 23 - Loss: 5.8345, Acc: 0.4219\n",
            "Epoch 24 - Loss: 5.3596, Acc: 0.4219\n",
            "Epoch 25 - Loss: 7.6101, Acc: 0.3750\n",
            "Epoch 26 - Loss: 5.3295, Acc: 0.5625\n",
            "Epoch 27 - Loss: 5.6158, Acc: 0.4688\n",
            "Epoch 28 - Loss: 5.1102, Acc: 0.5312\n",
            "Epoch 29 - Loss: 5.5252, Acc: 0.4062\n",
            "Epoch 30 - Loss: 5.6536, Acc: 0.5625\n",
            "Epoch 31 - Loss: 5.2795, Acc: 0.5156\n",
            "Epoch 32 - Loss: 5.2888, Acc: 0.5469\n",
            "Epoch 33 - Loss: 5.3519, Acc: 0.4688\n",
            "Epoch 34 - Loss: 4.6282, Acc: 0.6250\n",
            "Epoch 35 - Loss: 5.8261, Acc: 0.4688\n",
            "Epoch 36 - Loss: 4.6666, Acc: 0.5938\n",
            "Epoch 37 - Loss: 4.6957, Acc: 0.5312\n",
            "Epoch 38 - Loss: 5.6183, Acc: 0.4531\n",
            "Epoch 39 - Loss: 4.9865, Acc: 0.5156\n",
            "Epoch 40 - Loss: 4.5921, Acc: 0.6406\n",
            "Epoch 41 - Loss: 4.4055, Acc: 0.6250\n",
            "Epoch 42 - Loss: 5.2165, Acc: 0.6094\n",
            "Epoch 43 - Loss: 4.8002, Acc: 0.6094\n",
            "Epoch 44 - Loss: 4.3844, Acc: 0.5625\n",
            "Epoch 45 - Loss: 4.7108, Acc: 0.5938\n",
            "Epoch 46 - Loss: 4.3222, Acc: 0.6562\n",
            "Epoch 47 - Loss: 4.7372, Acc: 0.5312\n",
            "Epoch 48 - Loss: 4.6701, Acc: 0.5625\n",
            "Epoch 49 - Loss: 5.6001, Acc: 0.4062\n",
            "Epoch 50 - Loss: 4.0049, Acc: 0.6094\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>overfit_acc</td><td>▁▂▄▃▃▂▃▃▃▄▄▅▅▆▅▅▆▆▅▅▇▆▆▅▇▇▆█▆▆▆██▇▇▇█▆▇▇</td></tr><tr><td>overfit_epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>overfit_loss</td><td>█▇▆▅▆▅▅▆▄▄▄▄▄▃▄▃▃▃▃▃▃▃▂▃▃▃▃▂▃▂▃▂▂▂▂▂▁▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>overfit_acc</td><td>0.60938</td></tr><tr><td>overfit_epoch</td><td>50</td></tr><tr><td>overfit_loss</td><td>4.00486</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">overfit_test_v4</strong> at: <a href='https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN/runs/s4275988' target=\"_blank\">https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN/runs/s4275988</a><br> View project at: <a href='https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN' target=\"_blank\">https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250607_152029-s4275988/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "def train_model(model, config):\n",
        "    wandb.init(project=\"FER-CNN\", config=config)\n",
        "\n",
        "    # Transforms\n",
        "    train_transform = A.Compose([\n",
        "        A.HorizontalFlip(p=0.3),\n",
        "        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=10, p=0.3),\n",
        "        A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.3),\n",
        "        A.Normalize(mean=[0.5], std=[0.5]),\n",
        "        ToTensorV2()\n",
        "    ])\n",
        "\n",
        "    val_transform = A.Compose([\n",
        "        A.Normalize(mean=[0.5], std=[0.5]),\n",
        "        ToTensorV2()\n",
        "    ])\n",
        "\n",
        "    # Recreate datasets\n",
        "    train_dataset = FERDataset(train_imgs, train_labels, train_transform)\n",
        "    val_dataset = FERDataset(val_imgs, val_labels, val_transform)\n",
        "\n",
        "    # Handle class imbalance\n",
        "    class_counts = Counter(train_labels)\n",
        "    num_samples = len(train_labels)\n",
        "    class_weights = {i: num_samples / (len(class_counts) * count) for i, count in class_counts.items()}\n",
        "    sample_weights = [class_weights[label] for label in train_labels]\n",
        "    sampler = torch.utils.data.WeightedRandomSampler(sample_weights, num_samples)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], sampler=sampler)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=config['batch_size'])\n",
        "\n",
        "    model = model.to(device)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=config['lr'], weight_decay=config['weight_decay'])\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=1, eta_min=1e-6)\n",
        "\n",
        "    # Focal Loss\n",
        "    weights_tensor = torch.tensor([class_weights[i] for i in range(len(class_weights))]).float().to(device)\n",
        "    criterion = FocalLoss(gamma=2.0, weight=weights_tensor)\n",
        "\n",
        "    # Metrics\n",
        "    metrics = {\n",
        "        'conf_matrix': MulticlassConfusionMatrix(num_classes=7).to(device),\n",
        "        'f1': MulticlassF1Score(num_classes=7, average='macro').to(device),\n",
        "        'precision': MulticlassPrecision(num_classes=7, average='macro').to(device),\n",
        "        'recall': MulticlassRecall(num_classes=7, average='macro').to(device)\n",
        "    }\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(config['epochs']):\n",
        "        model.train()\n",
        "        train_loss, train_correct = 0.0, 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            train_correct += (outputs.argmax(1) == labels).sum().item()\n",
        "\n",
        "        train_acc = train_correct / len(train_loader.dataset)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss, val_correct = 0.0, 0\n",
        "        all_preds, all_labels = [], []\n",
        "\n",
        "        for metric in metrics.values():\n",
        "            metric.reset()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                preds = outputs.argmax(1)\n",
        "                val_correct += (preds == labels).sum().item()\n",
        "\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "                for metric in metrics.values():\n",
        "                    metric.update(preds, labels)\n",
        "\n",
        "        val_acc = val_correct / len(val_loader.dataset)\n",
        "        scheduler.step()\n",
        "\n",
        "        # Compute metrics safely\n",
        "        metric_results = {}\n",
        "        for name, metric in metrics.items():\n",
        "            result = metric.compute().detach().cpu()\n",
        "            if result.numel() == 1:\n",
        "                metric_results[name] = result.item()\n",
        "            else:\n",
        "                metric_results[name] = wandb.Histogram(result.numpy())\n",
        "\n",
        "        # Log to wandb\n",
        "        wandb.log({\n",
        "            'epoch': epoch + 1,\n",
        "            'train_loss': train_loss / len(train_loader),\n",
        "            'train_acc': train_acc,\n",
        "            'val_loss': val_loss / len(val_loader),\n",
        "            'val_acc': val_acc,\n",
        "            'lr': optimizer.param_groups[0]['lr'],\n",
        "            **metric_results\n",
        "        })\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{config['epochs']} - Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "        # Early stopping\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            patience_counter = 0\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= config['patience']:\n",
        "                print(f\"Early stopping at epoch {epoch+1}\")\n",
        "                break\n",
        "\n",
        "    # Final evaluation and confusion matrix\n",
        "    model.load_state_dict(torch.load('best_model.pth'))\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            preds = outputs.argmax(1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
        "    ax.set_xlabel(\"Predicted\")\n",
        "    ax.set_ylabel(\"True\")\n",
        "    ax.set_title(\"Confusion Matrix\")\n",
        "    wandb.log({\"confusion_matrix\": wandb.Image(fig)})\n",
        "    plt.close(fig)\n",
        "\n",
        "    # Classification report\n",
        "    report = classification_report(\n",
        "        all_labels, all_preds,\n",
        "        target_names=['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral'],\n",
        "        digits=4\n",
        "    )\n",
        "    print(report)\n",
        "    wandb.run.summary[\"classification_report\"] = report\n",
        "\n",
        "    # Save model as artifact\n",
        "    artifact = wandb.Artifact(f\"{config['model_name']}_model\", type=\"model\")\n",
        "    artifact.add_file(\"best_model.pth\")\n",
        "    wandb.log_artifact(artifact)\n",
        "    wandb.finish()\n",
        "\n",
        "\n",
        "# Focal Loss implementation\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=2.0, weight=None):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.weight = weight\n",
        "        self.ce = nn.CrossEntropyLoss(weight=weight)\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        logpt = -self.ce(input, target)\n",
        "        pt = torch.exp(logpt)\n",
        "        loss = -((1 - pt) ** self.gamma) * logpt\n",
        "        return loss.mean()"
      ],
      "metadata": {
        "id": "Qym8e1IWL2CG"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 1: Basic CNN\n",
        "config = {\n",
        "    'model_name': 'basic_cnn',\n",
        "    'lr': 0.001,\n",
        "    'batch_size': 64,\n",
        "    'epochs': 50,\n",
        "    'weight_decay': 1e-4,\n",
        "    'patience': 10\n",
        "}\n",
        "train_model(BasicFERModel(), config)\n",
        "\n",
        "# Experiment 2: Residual Network\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = self.shortcut(x)\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNetFER(nn.Module):\n",
        "    def __init__(self, num_classes=7):\n",
        "        super(ResNetFER, self).__init__()\n",
        "        self.in_channels = 32\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = self.make_layer(32, 2, stride=1)\n",
        "        self.layer2 = self.make_layer(64, 2, stride=2)\n",
        "        self.layer3 = self.make_layer(128, 2, stride=2)\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(128, num_classes)\n",
        "\n",
        "    def make_layer(self, out_channels, blocks, stride):\n",
        "        layers = []\n",
        "        layers.append(ResidualBlock(self.in_channels, out_channels, stride))\n",
        "        self.in_channels = out_channels\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(ResidualBlock(out_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.avg_pool(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "# Train ResNet\n",
        "config_resnet = {\n",
        "    'model_name': 'resnet',\n",
        "    'lr': 0.001,\n",
        "    'batch_size': 64,\n",
        "    'epochs': 50,\n",
        "    'weight_decay': 1e-4,\n",
        "    'patience': 10\n",
        "}\n",
        "train_model(ResNetFER(), config_resnet)\n",
        "\n",
        "# Experiment 3: Vision Transformer (small version)\n",
        "class ViTFER(nn.Module):\n",
        "    def __init__(self, num_classes=7, image_size=48, patch_size=8, dim=64, depth=4, heads=4):\n",
        "        super(ViTFER, self).__init__()\n",
        "        num_patches = (image_size // patch_size) ** 2\n",
        "        patch_dim = 1 * patch_size ** 2\n",
        "\n",
        "        self.patch_size = patch_size\n",
        "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n",
        "        self.patch_to_embedding = nn.Linear(patch_dim, dim)\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
        "\n",
        "        self.transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(d_model=dim, nhead=heads),\n",
        "            num_layers=depth\n",
        "        )\n",
        "\n",
        "        self.to_cls_token = nn.Identity()\n",
        "        self.mlp_head = nn.Sequential(\n",
        "            nn.Linear(dim, dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(dim // 2, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        p = self.patch_size\n",
        "        bs, c, h, w = img.shape\n",
        "        img = img.unfold(2, p, p).unfold(3, p, p)\n",
        "        img = img.contiguous().view(bs, c, -1, p, p)\n",
        "        img = img.permute(0, 2, 3, 4, 1)\n",
        "        img = img.contiguous().view(bs, -1, p * p * c)\n",
        "\n",
        "        x = self.patch_to_embedding(img)\n",
        "        cls_tokens = self.cls_token.expand(bs, -1, -1)\n",
        "        x = torch.cat((cls_tokens, x), dim=1)\n",
        "        x += self.pos_embedding\n",
        "        x = self.transformer(x)\n",
        "        x = self.to_cls_token(x[:, 0])\n",
        "        return self.mlp_head(x)\n",
        "\n",
        "\n",
        "# Train ViT\n",
        "config_vit = {\n",
        "    'model_name': 'vit',\n",
        "    'lr': 0.0005,  # Lower LR for ViT\n",
        "    'batch_size': 32,  # Smaller batch size due to memory\n",
        "    'epochs': 50,\n",
        "    'weight_decay': 1e-4,\n",
        "    'patience': 10\n",
        "}\n",
        "train_model(ViTFER(), config_vit)"
      ],
      "metadata": {
        "id": "YjWQjq7PeYhq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b167254a-2fa5-4dcb-8218-2bf23ec62657"
      },
      "execution_count": 32,
      "outputs": [
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250607_160313-o8wf7csh</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN/runs/o8wf7csh' target=\"_blank\">deft-gorge-24</a></strong> to <a href='https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN' target=\"_blank\">https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN/runs/o8wf7csh' target=\"_blank\">https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN/runs/o8wf7csh</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50 - Train Acc: 0.2562, Val Acc: 0.1456\n",
            "Epoch 2/50 - Train Acc: 0.3535, Val Acc: 0.3163\n",
            "Epoch 3/50 - Train Acc: 0.4126, Val Acc: 0.4009\n",
            "Epoch 4/50 - Train Acc: 0.4348, Val Acc: 0.4026\n",
            "Epoch 5/50 - Train Acc: 0.4625, Val Acc: 0.4330\n",
            "Epoch 6/50 - Train Acc: 0.4800, Val Acc: 0.4573\n",
            "Epoch 7/50 - Train Acc: 0.4949, Val Acc: 0.4716\n",
            "Epoch 8/50 - Train Acc: 0.5031, Val Acc: 0.4772\n",
            "Epoch 9/50 - Train Acc: 0.5051, Val Acc: 0.4859\n",
            "Epoch 10/50 - Train Acc: 0.5105, Val Acc: 0.4866\n",
            "Epoch 11/50 - Train Acc: 0.4926, Val Acc: 0.4678\n",
            "Epoch 12/50 - Train Acc: 0.5002, Val Acc: 0.4876\n",
            "Epoch 13/50 - Train Acc: 0.5086, Val Acc: 0.5110\n",
            "Epoch 14/50 - Train Acc: 0.5221, Val Acc: 0.5127\n",
            "Epoch 15/50 - Train Acc: 0.5322, Val Acc: 0.4998\n",
            "Epoch 16/50 - Train Acc: 0.5392, Val Acc: 0.5155\n",
            "Epoch 17/50 - Train Acc: 0.5505, Val Acc: 0.5246\n",
            "Epoch 18/50 - Train Acc: 0.5538, Val Acc: 0.5326\n",
            "Epoch 19/50 - Train Acc: 0.5581, Val Acc: 0.5402\n",
            "Epoch 20/50 - Train Acc: 0.5602, Val Acc: 0.5392\n",
            "Epoch 21/50 - Train Acc: 0.5448, Val Acc: 0.5016\n",
            "Epoch 22/50 - Train Acc: 0.5454, Val Acc: 0.5186\n",
            "Epoch 23/50 - Train Acc: 0.5447, Val Acc: 0.5246\n",
            "Epoch 24/50 - Train Acc: 0.5573, Val Acc: 0.5367\n",
            "Epoch 25/50 - Train Acc: 0.5682, Val Acc: 0.5399\n",
            "Epoch 26/50 - Train Acc: 0.5754, Val Acc: 0.5528\n",
            "Epoch 27/50 - Train Acc: 0.5800, Val Acc: 0.5573\n",
            "Epoch 28/50 - Train Acc: 0.5834, Val Acc: 0.5583\n",
            "Epoch 29/50 - Train Acc: 0.5878, Val Acc: 0.5664\n",
            "Epoch 30/50 - Train Acc: 0.5892, Val Acc: 0.5604\n",
            "Epoch 31/50 - Train Acc: 0.5723, Val Acc: 0.5444\n",
            "Epoch 32/50 - Train Acc: 0.5761, Val Acc: 0.5510\n",
            "Epoch 33/50 - Train Acc: 0.5775, Val Acc: 0.5409\n",
            "Epoch 34/50 - Train Acc: 0.5858, Val Acc: 0.5650\n",
            "Epoch 35/50 - Train Acc: 0.5873, Val Acc: 0.5625\n",
            "Epoch 36/50 - Train Acc: 0.5997, Val Acc: 0.5625\n",
            "Epoch 37/50 - Train Acc: 0.6075, Val Acc: 0.5643\n",
            "Epoch 38/50 - Train Acc: 0.6072, Val Acc: 0.5726\n",
            "Epoch 39/50 - Train Acc: 0.6121, Val Acc: 0.5761\n",
            "Epoch 40/50 - Train Acc: 0.6084, Val Acc: 0.5810\n",
            "Epoch 41/50 - Train Acc: 0.5971, Val Acc: 0.5559\n",
            "Epoch 42/50 - Train Acc: 0.5937, Val Acc: 0.5482\n",
            "Epoch 43/50 - Train Acc: 0.5911, Val Acc: 0.5646\n",
            "Epoch 44/50 - Train Acc: 0.6014, Val Acc: 0.5664\n",
            "Epoch 45/50 - Train Acc: 0.6036, Val Acc: 0.5751\n",
            "Epoch 46/50 - Train Acc: 0.6140, Val Acc: 0.5785\n",
            "Epoch 47/50 - Train Acc: 0.6125, Val Acc: 0.5723\n",
            "Epoch 48/50 - Train Acc: 0.6216, Val Acc: 0.5810\n",
            "Epoch 49/50 - Train Acc: 0.6245, Val Acc: 0.5772\n",
            "Epoch 50/50 - Train Acc: 0.6231, Val Acc: 0.5813\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Angry     0.5080    0.5564    0.5311       399\n",
            "     Disgust     0.3780    0.7045    0.4921        44\n",
            "        Fear     0.4585    0.2829    0.3499       410\n",
            "       Happy     0.8675    0.6801    0.7624       722\n",
            "         Sad     0.4693    0.5072    0.4876       483\n",
            "    Surprise     0.6185    0.8233    0.7064       317\n",
            "     Neutral     0.5144    0.6109    0.5585       496\n",
            "\n",
            "    accuracy                         0.5813      2871\n",
            "   macro avg     0.5449    0.5951    0.5554      2871\n",
            "weighted avg     0.5962    0.5813    0.5796      2871\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>f1</td><td>▁▄▅▅▅▆▆▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇█▇▇▇█▇▇▇██▇▇▇█████</td></tr><tr><td>lr</td><td>█▇▇▆▄▂▂▁██▆▄▃▂▂██▇▇▄▂▂▁██▇▆▄▃▂▁██▇▇▄▃▂▂█</td></tr><tr><td>precision</td><td>▁▃▄▄▄▄▄▅▅▅▆▅▅▅▆▆▆▅▆▆▆▆▇▇▇▆▆▇▇▇▇██▇▆▇█▇██</td></tr><tr><td>recall</td><td>▁▄▅▅▆▆▆▇▇▆▇▇▇▇▇█▇▇▇▇█████▇▇███████▇█████</td></tr><tr><td>train_acc</td><td>▁▃▄▄▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████▇▇█████</td></tr><tr><td>train_loss</td><td>█▅▄▄▃▃▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▄▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇████▇▇███████▇██████</td></tr><tr><td>val_loss</td><td>█▄▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>classification_report</td><td>              precis...</td></tr><tr><td>epoch</td><td>50</td></tr><tr><td>f1</td><td>0.55542</td></tr><tr><td>lr</td><td>0.001</td></tr><tr><td>precision</td><td>0.5449</td></tr><tr><td>recall</td><td>0.59506</td></tr><tr><td>train_acc</td><td>0.62307</td></tr><tr><td>train_loss</td><td>0.07</td></tr><tr><td>val_acc</td><td>0.58133</td></tr><tr><td>val_loss</td><td>0.59702</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">deft-gorge-24</strong> at: <a href='https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN/runs/o8wf7csh' target=\"_blank\">https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN/runs/o8wf7csh</a><br> View project at: <a href='https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN' target=\"_blank\">https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250607_160313-o8wf7csh/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250607_161007-tqv3v1q9</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN/runs/tqv3v1q9' target=\"_blank\">still-river-25</a></strong> to <a href='https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN' target=\"_blank\">https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN/runs/tqv3v1q9' target=\"_blank\">https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN/runs/tqv3v1q9</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50 - Train Acc: 0.1912, Val Acc: 0.0763\n",
            "Epoch 2/50 - Train Acc: 0.3151, Val Acc: 0.2699\n",
            "Epoch 3/50 - Train Acc: 0.4179, Val Acc: 0.3800\n",
            "Epoch 4/50 - Train Acc: 0.4998, Val Acc: 0.4103\n",
            "Epoch 5/50 - Train Acc: 0.5435, Val Acc: 0.5120\n",
            "Epoch 6/50 - Train Acc: 0.5689, Val Acc: 0.4904\n",
            "Epoch 7/50 - Train Acc: 0.5930, Val Acc: 0.5082\n",
            "Epoch 8/50 - Train Acc: 0.6140, Val Acc: 0.5535\n",
            "Epoch 9/50 - Train Acc: 0.6258, Val Acc: 0.5517\n",
            "Epoch 10/50 - Train Acc: 0.6374, Val Acc: 0.5611\n",
            "Epoch 11/50 - Train Acc: 0.5547, Val Acc: 0.4622\n",
            "Epoch 12/50 - Train Acc: 0.5818, Val Acc: 0.4723\n",
            "Epoch 13/50 - Train Acc: 0.6065, Val Acc: 0.4197\n",
            "Epoch 14/50 - Train Acc: 0.6154, Val Acc: 0.5545\n",
            "Epoch 15/50 - Train Acc: 0.6418, Val Acc: 0.5113\n",
            "Epoch 16/50 - Train Acc: 0.6570, Val Acc: 0.5347\n",
            "Epoch 17/50 - Train Acc: 0.6781, Val Acc: 0.5448\n",
            "Epoch 18/50 - Train Acc: 0.6852, Val Acc: 0.6047\n",
            "Epoch 19/50 - Train Acc: 0.6959, Val Acc: 0.6095\n",
            "Epoch 20/50 - Train Acc: 0.7030, Val Acc: 0.6001\n",
            "Epoch 21/50 - Train Acc: 0.6135, Val Acc: 0.5413\n",
            "Epoch 22/50 - Train Acc: 0.6377, Val Acc: 0.5636\n",
            "Epoch 23/50 - Train Acc: 0.6569, Val Acc: 0.5420\n",
            "Epoch 24/50 - Train Acc: 0.6680, Val Acc: 0.5862\n",
            "Epoch 25/50 - Train Acc: 0.6933, Val Acc: 0.5946\n",
            "Epoch 26/50 - Train Acc: 0.7069, Val Acc: 0.5974\n",
            "Epoch 27/50 - Train Acc: 0.7201, Val Acc: 0.5897\n",
            "Epoch 28/50 - Train Acc: 0.7343, Val Acc: 0.6109\n",
            "Epoch 29/50 - Train Acc: 0.7441, Val Acc: 0.6231\n",
            "Epoch 30/50 - Train Acc: 0.7483, Val Acc: 0.6235\n",
            "Epoch 31/50 - Train Acc: 0.6538, Val Acc: 0.5420\n",
            "Epoch 32/50 - Train Acc: 0.6793, Val Acc: 0.5657\n",
            "Epoch 33/50 - Train Acc: 0.6956, Val Acc: 0.5340\n",
            "Epoch 34/50 - Train Acc: 0.7124, Val Acc: 0.6075\n",
            "Epoch 35/50 - Train Acc: 0.7325, Val Acc: 0.6148\n",
            "Epoch 36/50 - Train Acc: 0.7559, Val Acc: 0.6120\n",
            "Epoch 37/50 - Train Acc: 0.7604, Val Acc: 0.6144\n",
            "Epoch 38/50 - Train Acc: 0.7746, Val Acc: 0.6395\n",
            "Epoch 39/50 - Train Acc: 0.7861, Val Acc: 0.6360\n",
            "Epoch 40/50 - Train Acc: 0.7912, Val Acc: 0.6381\n",
            "Epoch 41/50 - Train Acc: 0.6836, Val Acc: 0.5984\n",
            "Epoch 42/50 - Train Acc: 0.7156, Val Acc: 0.5876\n",
            "Epoch 43/50 - Train Acc: 0.7351, Val Acc: 0.6106\n",
            "Epoch 44/50 - Train Acc: 0.7481, Val Acc: 0.6116\n",
            "Epoch 45/50 - Train Acc: 0.7659, Val Acc: 0.6238\n",
            "Epoch 46/50 - Train Acc: 0.7818, Val Acc: 0.6158\n",
            "Epoch 47/50 - Train Acc: 0.7928, Val Acc: 0.6378\n",
            "Epoch 48/50 - Train Acc: 0.8078, Val Acc: 0.6395\n",
            "Early stopping at epoch 48\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Angry     0.5469    0.5840    0.5648       399\n",
            "     Disgust     0.6279    0.6136    0.6207        44\n",
            "        Fear     0.4913    0.4829    0.4871       410\n",
            "       Happy     0.8746    0.7922    0.8314       722\n",
            "         Sad     0.5515    0.4990    0.5239       483\n",
            "    Surprise     0.7343    0.8107    0.7706       317\n",
            "     Neutral     0.5520    0.6210    0.5844       496\n",
            "\n",
            "    accuracy                         0.6395      2871\n",
            "   macro avg     0.6255    0.6291    0.6261      2871\n",
            "weighted avg     0.6450    0.6395    0.6408      2871\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>f1</td><td>▁▃▄▅▆▆▆▇▇▅▅▇▆▇▇█▇▆▇▆▇▇▇██▆▇▇▇█████▇▇▇███</td></tr><tr><td>lr</td><td>█▇▇▆▄▂▂▁██▇▆▄▃▂▁██▇▇▄▃▂▂▁█▇▇▆▄▂▂▁██▇▆▄▃▂</td></tr><tr><td>precision</td><td>▁▄▄▄▅▆▆▆▆▅▅▇▆▆▆▇▇▆▆▇▇▇▇██▆▇▇▇▇▇████▇▇▇▇█</td></tr><tr><td>recall</td><td>▁▃▅▅▆▇▇▇▇▆▅▆▆▇▇██▇▇▆▇▇███▇▇▇▇█████▇█████</td></tr><tr><td>train_acc</td><td>▁▂▄▅▅▆▆▆▆▅▆▆▆▆▇▇▇▆▆▆▇▇▇▇▇▆▇▇▇▇▇███▇▇▇███</td></tr><tr><td>train_loss</td><td>█▅▄▃▂▂▂▂▂▂▂▂▂▁▁▁▁▂▂▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▃▅▅▆▆▇▇▇▆▅▇▆▇▇██▇▇▇▇▇▇██▇▇▇██████▇█████</td></tr><tr><td>val_loss</td><td>█▅▃▂▂▁▁▁▁▂▂▃▂▂▁▁▁▂▂▃▁▁▁▁▁▁▂▂▂▁▁▂▁▁▂▁▁▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>classification_report</td><td>              precis...</td></tr><tr><td>epoch</td><td>48</td></tr><tr><td>f1</td><td>0.62784</td></tr><tr><td>lr</td><td>0.0001</td></tr><tr><td>precision</td><td>0.63398</td></tr><tr><td>recall</td><td>0.62653</td></tr><tr><td>train_acc</td><td>0.80784</td></tr><tr><td>train_loss</td><td>0.01292</td></tr><tr><td>val_acc</td><td>0.6395</td></tr><tr><td>val_loss</td><td>0.65134</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">still-river-25</strong> at: <a href='https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN/runs/tqv3v1q9' target=\"_blank\">https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN/runs/tqv3v1q9</a><br> View project at: <a href='https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN' target=\"_blank\">https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250607_161007-tqv3v1q9/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250607_162637-1ta91gp9</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN/runs/1ta91gp9' target=\"_blank\">glamorous-glitter-26</a></strong> to <a href='https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN' target=\"_blank\">https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN/runs/1ta91gp9' target=\"_blank\">https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN/runs/1ta91gp9</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50 - Train Acc: 0.1398, Val Acc: 0.0153\n",
            "Epoch 2/50 - Train Acc: 0.1453, Val Acc: 0.0153\n",
            "Epoch 3/50 - Train Acc: 0.1464, Val Acc: 0.0153\n",
            "Epoch 4/50 - Train Acc: 0.1391, Val Acc: 0.0153\n",
            "Epoch 5/50 - Train Acc: 0.1454, Val Acc: 0.0153\n",
            "Epoch 6/50 - Train Acc: 0.1435, Val Acc: 0.0153\n",
            "Epoch 7/50 - Train Acc: 0.1437, Val Acc: 0.0153\n",
            "Epoch 8/50 - Train Acc: 0.1449, Val Acc: 0.0153\n",
            "Epoch 9/50 - Train Acc: 0.1458, Val Acc: 0.0153\n",
            "Epoch 10/50 - Train Acc: 0.1412, Val Acc: 0.0153\n",
            "Epoch 11/50 - Train Acc: 0.1468, Val Acc: 0.0153\n",
            "Early stopping at epoch 11\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Angry     0.0000    0.0000    0.0000       399\n",
            "     Disgust     0.0153    1.0000    0.0302        44\n",
            "        Fear     0.0000    0.0000    0.0000       410\n",
            "       Happy     0.0000    0.0000    0.0000       722\n",
            "         Sad     0.0000    0.0000    0.0000       483\n",
            "    Surprise     0.0000    0.0000    0.0000       317\n",
            "     Neutral     0.0000    0.0000    0.0000       496\n",
            "\n",
            "    accuracy                         0.0153      2871\n",
            "   macro avg     0.0022    0.1429    0.0043      2871\n",
            "weighted avg     0.0002    0.0153    0.0005      2871\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▂▃▄▅▅▆▇▇█</td></tr><tr><td>f1</td><td>▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>█▇▇▆▄▃▂▂▁██</td></tr><tr><td>precision</td><td>▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>recall</td><td>▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▂▇█▁▇▅▅▆▇▃█</td></tr><tr><td>train_loss</td><td>▇▃▁█▂▅▄▅▂▆▂</td></tr><tr><td>val_acc</td><td>▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▆█▁▆▄▅▅▄▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>classification_report</td><td>              precis...</td></tr><tr><td>epoch</td><td>11</td></tr><tr><td>f1</td><td>0.00431</td></tr><tr><td>lr</td><td>0.00049</td></tr><tr><td>precision</td><td>0.00219</td></tr><tr><td>recall</td><td>0.14286</td></tr><tr><td>train_acc</td><td>0.14684</td></tr><tr><td>train_loss</td><td>0.77897</td></tr><tr><td>val_acc</td><td>0.01533</td></tr><tr><td>val_loss</td><td>2.15203</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">glamorous-glitter-26</strong> at: <a href='https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN/runs/1ta91gp9' target=\"_blank\">https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN/runs/1ta91gp9</a><br> View project at: <a href='https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN' target=\"_blank\">https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250607_162637-1ta91gp9/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZfRCch1RO9QV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNsjyHnwW5o7inboR0m+Uhy",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}