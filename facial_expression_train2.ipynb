{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AleksandreBakhtadze/ML-abakh22-facial-expression-recognition/blob/main/facial_expression_train2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvTGhVSzkkxT"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle\n",
        "!pip install -q wandb\n",
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "EcJz7VoUpteu",
        "outputId": "556b8374-730f-42ff-9e35-967b64896143"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mabakh22\u001b[0m (\u001b[33mabakh22-free-university-of-tbilisi-\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading challenges-in-representation-learning-facial-expression-recognition-challenge.zip to /content\n",
            " 86% 246M/285M [00:01<00:00, 132MB/s] \n",
            "100% 285M/285M [00:03<00:00, 77.6MB/s]\n"
          ]
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.login()\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c challenges-in-representation-learning-facial-expression-recognition-challenge\n",
        "!unzip -q challenges-in-representation-learning-facial-expression-recognition-challenge.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5AAtI1pvEci"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchmetrics.classification import MulticlassConfusionMatrix, MulticlassPrecision, MulticlassRecall, MulticlassF1Score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from torchsummary import summary\n",
        "import numpy as np\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV\n",
        "df = pd.read_csv(\"train.csv\")\n",
        "\n",
        "# Example row\n",
        "print(df.head())\n",
        "\n",
        "# Convert the pixel values to image tensors\n",
        "def process_row(row):\n",
        "    pixels = np.array([int(p) for p in row['pixels'].split()], dtype=np.uint8).reshape(48, 48)\n",
        "    img = Image.fromarray(pixels)\n",
        "    return img, int(row['emotion'])\n",
        "\n",
        "images, labels = zip(*[process_row(row) for _, row in df.iterrows()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdcpG1aPLqs3",
        "outputId": "4ead8e23-174f-4280-8380-29b9ce61888f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   emotion                                             pixels\n",
            "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...\n",
            "1        0  151 150 147 155 148 133 111 140 170 174 182 15...\n",
            "2        2  231 212 156 164 174 138 161 173 182 200 106 38...\n",
            "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...\n",
            "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "\n",
        "class FERDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, images, labels, transform=None):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.images[idx]\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, self.labels[idx]\n",
        "\n",
        "# Split into train and val\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_imgs, val_imgs, train_labels, val_labels = train_test_split(images, labels, test_size=0.1, stratify=labels)\n",
        "\n",
        "train_dataset = FERDataset(train_imgs, train_labels, transform)\n",
        "val_dataset = FERDataset(val_imgs, val_labels, transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64)\n"
      ],
      "metadata": {
        "id": "zPeFplGtLq2T"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImprovedCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImprovedCNN, self).__init__()\n",
        "        self.conv_block1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.conv_block2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.conv_block3 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(256 * 6 * 6, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 7)  # Assuming 7 emotion classes\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_block1(x)\n",
        "        x = self.conv_block2(x)\n",
        "        x = self.conv_block3(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "model = ImprovedCNN().to('cuda' if torch.cuda.is_available() else 'gpu')\n",
        "summary(model, (1, 48, 48))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYYw3h4PLq7l",
        "outputId": "ccfcb1ba-8906-4821-8e7b-d34e20775110"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 48, 48]             640\n",
            "       BatchNorm2d-2           [-1, 64, 48, 48]             128\n",
            "              ReLU-3           [-1, 64, 48, 48]               0\n",
            "         MaxPool2d-4           [-1, 64, 24, 24]               0\n",
            "            Conv2d-5          [-1, 128, 24, 24]          73,856\n",
            "       BatchNorm2d-6          [-1, 128, 24, 24]             256\n",
            "              ReLU-7          [-1, 128, 24, 24]               0\n",
            "         MaxPool2d-8          [-1, 128, 12, 12]               0\n",
            "            Conv2d-9          [-1, 256, 12, 12]         295,168\n",
            "      BatchNorm2d-10          [-1, 256, 12, 12]             512\n",
            "             ReLU-11          [-1, 256, 12, 12]               0\n",
            "        MaxPool2d-12            [-1, 256, 6, 6]               0\n",
            "           Linear-13                  [-1, 512]       4,719,104\n",
            "             ReLU-14                  [-1, 512]               0\n",
            "          Dropout-15                  [-1, 512]               0\n",
            "           Linear-16                    [-1, 7]           3,591\n",
            "================================================================\n",
            "Total params: 5,093,255\n",
            "Trainable params: 5,093,255\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.41\n",
            "Params size (MB): 19.43\n",
            "Estimated Total Size (MB): 25.85\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample 20 training examples\n",
        "small_dataset, _ = torch.utils.data.random_split(train_dataset, [20, len(train_dataset) - 20])\n",
        "small_loader = torch.utils.data.DataLoader(small_dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "# Re-initialize the model\n",
        "model = ImprovedCNN().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "print(\"Training on a tiny dataset to check overfitting...\")\n",
        "for epoch in range(20):\n",
        "    model.train()\n",
        "    total_loss, correct = 0, 0\n",
        "    for imgs, labels in small_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        outputs = model(imgs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        correct += (outputs.argmax(1) == labels).sum().item()\n",
        "\n",
        "    acc = correct / len(small_loader.dataset)\n",
        "    print(f\"Epoch {epoch+1} - Loss: {total_loss:.4f}, Acc: {acc:.4f}\")\n",
        "    if acc == 1.0:\n",
        "        print(\"✅ Model successfully overfit tiny dataset\")\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuGPD0QfSMJT",
        "outputId": "9d7ea4e1-a5d1-4d30-b232-816f03d87006"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on a tiny dataset to check overfitting...\n",
            "Epoch 1 - Loss: 35.5255, Acc: 0.4000\n",
            "Epoch 2 - Loss: 30.5489, Acc: 0.3500\n",
            "Epoch 3 - Loss: 16.8105, Acc: 0.5000\n",
            "Epoch 4 - Loss: 9.2955, Acc: 0.5500\n",
            "Epoch 5 - Loss: 13.0531, Acc: 0.4500\n",
            "Epoch 6 - Loss: 14.3013, Acc: 0.6500\n",
            "Epoch 7 - Loss: 13.5415, Acc: 0.5500\n",
            "Epoch 8 - Loss: 5.1781, Acc: 0.7000\n",
            "Epoch 9 - Loss: 9.5160, Acc: 0.7000\n",
            "Epoch 10 - Loss: 1.6484, Acc: 0.9000\n",
            "Epoch 11 - Loss: 4.1305, Acc: 0.8500\n",
            "Epoch 12 - Loss: 2.6446, Acc: 0.8500\n",
            "Epoch 13 - Loss: 3.1666, Acc: 0.9000\n",
            "Epoch 14 - Loss: 0.0803, Acc: 1.0000\n",
            "✅ Model successfully overfit tiny dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Start Wandb\n",
        "wandb.init(project=\"FER-CNN\", name=\"simple_cnn_run\")\n",
        "\n",
        "# Loss & optimizer\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    train_loss, correct = 0, 0\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        outputs = model(imgs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        correct += (outputs.argmax(1) == labels).sum().item()\n",
        "\n",
        "    train_acc = correct / len(train_loader.dataset)\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    val_loss, val_correct = 0, 0\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in val_loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            preds = outputs.argmax(1)\n",
        "            val_correct += (preds == labels).sum().item()\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    val_acc = val_correct / len(val_loader.dataset)\n",
        "\n",
        "    wandb.log({\n",
        "        \"epoch\": epoch + 1,\n",
        "        \"train_loss\": train_loss,\n",
        "        \"train_acc\": train_acc,\n",
        "        \"val_loss\": val_loss,\n",
        "        \"val_acc\": val_acc\n",
        "    })\n",
        "\n",
        "    print(f\"Epoch {epoch+1} - Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "# Confusion matrix and classification report at the end\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "fig, ax = plt.subplots(figsize=(8,6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
        "ax.set_xlabel(\"Predicted\")\n",
        "ax.set_ylabel(\"True\")\n",
        "ax.set_title(\"Confusion Matrix\")\n",
        "wandb.log({\"confusion_matrix\": wandb.Image(fig)})\n",
        "plt.close(fig)\n",
        "\n",
        "# Classification report\n",
        "report = classification_report(all_labels, all_preds, digits=4)\n",
        "print(report)\n",
        "wandb.run.summary[\"classification_report\"] = report\n",
        "\n",
        "# Sample predictions\n",
        "model.eval()\n",
        "for i in range(5):\n",
        "    img, label = val_dataset[i]\n",
        "    with torch.no_grad():\n",
        "        pred = model(img.unsqueeze(0).to(device)).argmax(1).item()\n",
        "    img_np = img.squeeze().numpy()\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.imshow(img_np, cmap=\"gray\")\n",
        "    ax.set_title(f\"Predicted: {pred}, True: {label}\")\n",
        "    ax.axis('off')\n",
        "    wandb.log({f\"Example_{i}\": wandb.Image(fig)})\n",
        "    plt.close(fig)\n",
        "\n",
        "wandb.finish()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Qym8e1IWL2CG",
        "outputId": "5d95920a-dfcb-400c-e917-11cc2f16ba24"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250606_172945-vl4boqzo</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN/runs/vl4boqzo' target=\"_blank\">simple_cnn_run</a></strong> to <a href='https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN' target=\"_blank\">https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN/runs/vl4boqzo' target=\"_blank\">https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN/runs/vl4boqzo</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Train Acc: 0.2689, Val Acc: 0.3542\n",
            "Epoch 2 - Train Acc: 0.3518, Val Acc: 0.4016\n",
            "Epoch 3 - Train Acc: 0.3982, Val Acc: 0.4713\n",
            "Epoch 4 - Train Acc: 0.4185, Val Acc: 0.4974\n",
            "Epoch 5 - Train Acc: 0.4423, Val Acc: 0.4929\n",
            "Epoch 6 - Train Acc: 0.4611, Val Acc: 0.5023\n",
            "Epoch 7 - Train Acc: 0.4761, Val Acc: 0.5068\n",
            "Epoch 8 - Train Acc: 0.4858, Val Acc: 0.5082\n",
            "Epoch 9 - Train Acc: 0.4983, Val Acc: 0.5420\n",
            "Epoch 10 - Train Acc: 0.5045, Val Acc: 0.5482\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.4651    0.4010    0.4307       399\n",
            "           1     0.0000    0.0000    0.0000        44\n",
            "           2     0.3846    0.1220    0.1852       410\n",
            "           3     0.7736    0.8047    0.7889       722\n",
            "           4     0.3758    0.5735    0.4541       483\n",
            "           5     0.7464    0.6593    0.7002       317\n",
            "           6     0.4722    0.5988    0.5280       496\n",
            "\n",
            "    accuracy                         0.5482      2871\n",
            "   macro avg     0.4597    0.4513    0.4410      2871\n",
            "weighted avg     0.5413    0.5482    0.5296      2871\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_acc</td><td>▁▃▅▅▆▇▇▇██</td></tr><tr><td>train_loss</td><td>█▅▄▃▃▂▂▂▁▁</td></tr><tr><td>val_acc</td><td>▁▃▅▆▆▆▇▇██</td></tr><tr><td>val_loss</td><td>█▆▃▃▃▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>classification_report</td><td>              precis...</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>train_acc</td><td>0.50453</td></tr><tr><td>train_loss</td><td>503.31711</td></tr><tr><td>val_acc</td><td>0.54824</td></tr><tr><td>val_loss</td><td>54.97838</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">simple_cnn_run</strong> at: <a href='https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN/runs/vl4boqzo' target=\"_blank\">https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN/runs/vl4boqzo</a><br> View project at: <a href='https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN' target=\"_blank\">https://wandb.ai/abakh22-free-university-of-tbilisi-/FER-CNN</a><br>Synced 5 W&B file(s), 6 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250606_172945-vl4boqzo/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qf9vWdXNP_AF",
        "outputId": "76af8d24-3c8f-44cd-9489-69bf4dfcc770"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YjWQjq7PeYhq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPd2kD6i+bqRIO/oG8OcPQQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}